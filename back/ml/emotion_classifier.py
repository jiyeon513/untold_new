# back/ml/emotion_classifier.py
import torch
import os
from transformers import AutoTokenizer, AutoModel
import numpy as np
from huggingface_hub import hf_hub_download

# EmotionRegressor í´ë˜ìŠ¤ ì •ì˜ (í›ˆë ¨ ì‹œ ì‚¬ìš©í–ˆë˜ ê²ƒê³¼ ë™ì¼)
class EmotionRegressor(torch.nn.Module):
    def __init__(self, base_model):
        super().__init__()
        self.encoder = base_model
        # ëª¨ë¸ì˜ hidden sizeë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜´
        hidden_size = base_model.config.hidden_size
        self.regressor = torch.nn.Sequential(
            torch.nn.Linear(hidden_size, 2), # ì¶œë ¥: [valence, arousal] 2ê°œ
            torch.nn.Tanh()      # ê²°ê³¼ë¥¼ -1 ~ 1 ì‚¬ì´ë¡œ ì œí•œ
        )
    
    def forward(self, input_ids, attention_mask, labels=None):
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        cls_vector = outputs.last_hidden_state[:, 0]
        logits = self.regressor(cls_vector)
        loss = None
        if labels is not None:
            # íšŒê·€ ë¬¸ì œì´ë¯€ë¡œ MSELoss ì‚¬ìš©
            loss_fct = torch.nn.MSELoss()
            loss = loss_fct(logits, labels)
        return (loss, logits) if loss is not None else logits

def download_model_from_hub():
    """Hugging Face Hubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    print("ğŸ¤— Hugging Face Hubì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    
    REPO_ID = "kjy8402/untold-2d-emotion-model"
    files_to_download = [
        "model.safetensors",
        "tokenizer.json", 
        "tokenizer_config.json",
        "special_tokens_map.json",
        "training_args.bin"
    ]
    
    # ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„±
    download_dir = "ml/best_emotion_regressor"
    os.makedirs(download_dir, exist_ok=True)
    
    try:
        for filename in files_to_download:
            print(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {filename}")
            downloaded_path = hf_hub_download(
                repo_id=REPO_ID,
                filename=filename,
                local_dir=download_dir,
                local_dir_use_symlinks=False
            )
            print(f"âœ… ì™„ë£Œ: {filename}")
        
        print("ğŸ‰ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ (í•œ ë²ˆë§Œ ì‹¤í–‰)
print("2D ê°ì • ë¶„ì„ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")

# ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ
MODEL_NAME = "intfloat/multilingual-e5-large-instruct"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)
base_model = AutoModel.from_pretrained(MODEL_NAME, trust_remote_code=True)

# í›ˆë ¨ëœ ê°ì • íšŒê·€ ëª¨ë¸ ë¡œë“œ
model = EmotionRegressor(base_model)

# ëª¨ë¸ ê²½ë¡œ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ
model_paths = [
    "/root/UnTold/back/ml/best_emotion_regressor",  # GPU ì„œë²„ ê²½ë¡œ
    "ml/best_emotion_regressor",                   # ìƒëŒ€ ê²½ë¡œ
    "./best_emotion_regressor"                          # í˜„ì¬ ë””ë ‰í† ë¦¬
]

model_loaded = False
model_path = None

# ê¸°ì¡´ ëª¨ë¸ ê²½ë¡œë“¤ ì‹œë„
for path in model_paths:
    if os.path.exists(os.path.join(path, "model.safetensors")):
        model_path = path
        print(f"âœ… ë¡œì»¬ ëª¨ë¸ ë°œê²¬: {model_path}")
        break

# ë¡œì»¬ì— ëª¨ë¸ì´ ì—†ìœ¼ë©´ Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ
if not model_path:
    print("âš ï¸  ë¡œì»¬ì— ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    if download_model_from_hub():
        model_path = "ml/best_emotion_regressor"
    else:
        raise FileNotFoundError("ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
try:
    # safetensors ëŒ€ì‹  PyTorch ë°©ì‹ìœ¼ë¡œ ë¡œë“œ ì‹œë„
    checkpoint = torch.load(f"{model_path}/pytorch_model.bin", map_location='cpu')
    model.load_state_dict(checkpoint)
except FileNotFoundError:
    try:
        # Transformers ë°©ì‹ìœ¼ë¡œ ì‹œë„
        from safetensors.torch import load_file
        model_weights = load_file(f"{model_path}/model.safetensors")
        model.load_state_dict(model_weights)
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

model.eval()
print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

def get_emotion_label(valence, arousal):
    """
    Russellì˜ ê°ì • ëª¨ë¸ì— ê¸°ë°˜í•˜ì—¬ valence, arousal ê°’ì„ ê°ì • ë ˆì´ë¸”ë¡œ ë³€í™˜
    """
    if valence > 0.2:
        if arousal > 0.2:
            return "excited"  # í¥ë¶„
        elif arousal < -0.2:
            return "calm"     # í‰ì˜¨
        else:
            return "pleasant" # ì¦ê±°ì›€
    elif valence < -0.2:
        if arousal > 0.2:
            return "angry"    # ë¶„ë…¸
        elif arousal < -0.2:
            return "sad"      # ìŠ¬í””
        else:
            return "unpleasant" # ë¶ˆì¾Œ
    else:
        if arousal > 0.2:
            return "tense"    # ê¸´ì¥
        elif arousal < -0.2:
            return "relaxed"  # ì´ì™„
        else:
            return "neutral"  # ì¤‘ë¦½

def analyze_sentiment(text: str):
    """
    2ì°¨ì› ê°ì • íšŒê·€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Returns:
        dict: {
            "valence": float (-1 to 1, ë¶€ì •ì  -> ê¸ì •ì ),
            "arousal": float (-1 to 1, ë‚®ì€ ê°ì„± -> ë†’ì€ ê°ì„±),
            "emotion_label": str (Russell ëª¨ë¸ ê¸°ë°˜ ê°ì • ë ˆì´ë¸”),
            "confidence": float (ì˜ˆì¸¡ ì‹ ë¢°ë„)
        }
    """
    if not text:
        return {
            "valence": 0.0,
            "arousal": 0.0,
            "emotion_label": "neutral",
            "confidence": 1.0
        }

    try:
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° í† í¬ë‚˜ì´ì§•
        query = f"query: {text}"
        tokenized_input = tokenizer(
            query, 
            max_length=128, 
            truncation=True, 
            padding="max_length", 
            return_tensors="pt"
        )
        
        # ëª¨ë¸ ì˜ˆì¸¡
        with torch.no_grad():
            outputs = model(
                input_ids=tokenized_input["input_ids"],
                attention_mask=tokenized_input["attention_mask"]
            )
            
            # valence, arousal ê°’ ì¶”ì¶œ
            valence, arousal = outputs[0].numpy()
            
            # ê°ì • ë ˆì´ë¸” ìƒì„±
            emotion_label = get_emotion_label(valence, arousal)
            
            # ì‹ ë¢°ë„ ê³„ì‚° (0ì—ì„œ ë©€ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„)
            confidence = min(1.0, (abs(valence) + abs(arousal)) / 2.0 + 0.3)
            
            return {
                "valence": float(valence),
                "arousal": float(arousal),
                "emotion_label": emotion_label,
                "confidence": float(confidence)
            }

    except Exception as e:
        print(f"Error during sentiment analysis: {e}")
        return {
            "valence": 0.0,
            "arousal": 0.0,
            "emotion_label": "error",
            "confidence": 0.0
        }